CONSTRAINED OPTIMIZATION - LAGRANGE MULTIPLIERS AND KKT CONDITIONS
=====================================================================

TABLE OF CONTENTS:
1. Introduction to Constrained Optimization
2. Equality Constraints and Lagrange Multipliers
3. Inequality Constraints and KKT Conditions
4. Constraint Qualifications
5. Duality Theory
6. Computational Methods for Constrained Optimization
7. Special Cases and Applications
8. Machine Learning Applications

=======================================================

1. INTRODUCTION TO CONSTRAINED OPTIMIZATION
===========================================

1.1 Problem Formulation:
-----------------------
General constrained optimization problem:
minimize f(x)
subject to gᵢ(x) ≤ 0, i = 1, ..., m (inequality constraints)
          hⱼ(x) = 0, j = 1, ..., p (equality constraints)
          x ∈ X (domain constraints)

Components:
- Objective function: f: ℝⁿ → ℝ
- Inequality constraints: gᵢ: ℝⁿ → ℝ
- Equality constraints: hⱼ: ℝⁿ → ℝ
- Feasible set: S = {x : gᵢ(x) ≤ 0, hⱼ(x) = 0}

1.2 Types of Solutions:
----------------------
Feasible point: x ∈ S
Globally optimal: f(x*) ≤ f(x) for all x ∈ S
Locally optimal: f(x*) ≤ f(x) for all x ∈ S ∩ N(x*) where N(x*) is neighborhood

Active constraints at x*:
- Equality constraints: always active (hⱼ(x*) = 0)
- Inequality constraints: active if gᵢ(x*) = 0, inactive if gᵢ(x*) < 0

1.3 Examples:
------------
Linear programming:
minimize cᵀx
subject to Ax ≤ b
          x ≥ 0

Quadratic programming:
minimize ½xᵀQx + cᵀx
subject to Ax ≤ b
          Cx = d

Nonlinear programming: General case with nonlinear f, g, h

1.4 Geometric Interpretation:
----------------------------
Feasible set S is intersection of constraint sets
Optimality occurs where:
- Gradient of objective is normal to feasible set boundary
- Cannot improve objective while maintaining feasibility

Constraint surfaces:
- Equality constraints define manifolds (reduce dimension)
- Inequality constraints define half-spaces
- Active inequality constraints behave like equality constraints

=======================================================

2. EQUALITY CONSTRAINTS AND LAGRANGE MULTIPLIERS
================================================

2.1 Problem Setup:
-----------------
minimize f(x)
subject to h(x) = 0

where h: ℝⁿ → ℝᵖ with h(x) = [h₁(x), ..., hₚ(x)]ᵀ

Assume:
- f and h are continuously differentiable
- ∇h(x*) has full rank p (constraint qualification)

2.2 Method of Lagrange Multipliers:
----------------------------------
Lagrangian function:
L(x, λ) = f(x) + λᵀh(x) = f(x) + Σⱼ₌₁ᵖ λⱼhⱼ(x)

where λ = [λ₁, ..., λₚ]ᵀ are Lagrange multipliers

First-order necessary conditions (KKT conditions for equality constraints):
∇ₓL(x*, λ*) = ∇f(x*) + Σⱼ λⱼ*∇hⱼ(x*) = 0
∇λL(x*, λ*) = h(x*) = 0

2.3 Geometric Interpretation:
----------------------------
At optimal point x*:
∇f(x*) = -Σⱼ λⱼ*∇hⱼ(x*)

This means:
- Gradient of objective is linear combination of constraint gradients
- Objective gradient is normal to feasible manifold
- Cannot improve objective by moving along feasible directions

Lagrange multipliers λⱼ* represent:
- Shadow prices: Rate of change of optimal value w.r.t. constraint level
- Sensitivity of objective to constraint perturbations

2.4 Second-Order Conditions:
---------------------------
Let Z(x*) be matrix whose columns span null space of ∇h(x*)ᵀ
(tangent space to constraint manifold)

Second-order necessary condition:
ZᵀL(x*, λ*)Z ⪰ 0

where L(x, λ) = ∇²f(x) + Σⱼ λⱼ∇²hⱼ(x) is Hessian of Lagrangian

Second-order sufficient condition:
ZᵀL(x*, λ*)Z ≻ 0

Interpretation: Hessian of Lagrangian restricted to tangent space is positive definite

2.5 Computational Approach:
--------------------------
System of equations to solve:
∇f(x) + Σⱼ λⱼ∇hⱼ(x) = 0
h(x) = 0

This gives n + p equations in n + p unknowns (x, λ)

Methods:
- Newton's method on KKT system
- Elimination method (solve for x, then λ)
- Penalty methods
- Augmented Lagrangian methods

=======================================================

3. INEQUALITY CONSTRAINTS AND KKT CONDITIONS
============================================

3.1 Problem Setup:
-----------------
minimize f(x)
subject to g(x) ≤ 0
          h(x) = 0

where g: ℝⁿ → ℝᵐ, h: ℝⁿ → ℝᵖ

3.2 Karush-Kuhn-Tucker (KKT) Conditions:
----------------------------------------
Lagrangian: L(x, μ, λ) = f(x) + μᵀg(x) + λᵀh(x)

KKT necessary conditions:
1. Stationarity: ∇ₓL(x*, μ*, λ*) = 0
2. Primal feasibility: g(x*) ≤ 0, h(x*) = 0
3. Dual feasibility: μ* ≥ 0
4. Complementary slackness: μᵢ*gᵢ(x*) = 0 for all i

Expanded form:
∇f(x*) + Σᵢ μᵢ*∇gᵢ(x*) + Σⱼ λⱼ*∇hⱼ(x*) = 0
gᵢ(x*) ≤ 0, μᵢ* ≥ 0, μᵢ*gᵢ(x*) = 0 for all i
hⱼ(x*) = 0 for all j

3.3 Complementary Slackness:
---------------------------
For each inequality constraint gᵢ(x) ≤ 0:
- If gᵢ(x*) < 0 (inactive): then μᵢ* = 0
- If μᵢ* > 0: then gᵢ(x*) = 0 (active)

Interpretation:
- Inactive constraints don't affect optimality (μᵢ* = 0)
- Active constraints with positive multipliers are "binding"
- Active constraints with zero multipliers may be removed

3.4 KKT Sufficient Conditions:
-----------------------------
If KKT conditions hold and:
- f is convex
- gᵢ are convex for all i
- hⱼ are affine (linear) for all j

Then x* is globally optimal.

For non-convex problems:
- KKT conditions are only necessary (with constraint qualifications)
- May need second-order conditions for sufficiency

3.5 Second-Order Conditions:
---------------------------
Let I(x*) = {i : gᵢ(x*) = 0} be active inequality constraints

Critical cone: C(x*) = {d : ∇hⱼ(x*)ᵀd = 0 for all j,
                            ∇gᵢ(x*)ᵀd ≤ 0 for i ∈ I(x*)}

Second-order necessary condition:
dᵀ∇²ₓₓL(x*, μ*, λ*)d ≥ 0 for all d ∈ C(x*)

Second-order sufficient condition:
dᵀ∇²ₓₓL(x*, μ*, λ*)d > 0 for all d ∈ C(x*), d ≠ 0

=======================================================

4. CONSTRAINT QUALIFICATIONS
============================

4.1 Need for Constraint Qualifications:
---------------------------------------
KKT conditions may fail to hold at optimal points without proper conditions
Constraint qualifications ensure KKT conditions are necessary

4.2 Linear Independence Constraint Qualification (LICQ):
-------------------------------------------------------
Gradients of active constraints are linearly independent:
{∇gᵢ(x*) : i ∈ I(x*)} ∪ {∇hⱼ(x*) : j = 1, ..., p} are linearly independent

Properties:
- Strongest but most restrictive
- Ensures unique Lagrange multipliers
- Easy to check

4.3 Mangasarian-Fromovitz Constraint Qualification (MFCQ):
---------------------------------------------------------
Gradients of equality constraints are linearly independent, and
∃ d such that ∇hⱼ(x*)ᵀd = 0 for all j
           ∇gᵢ(x*)ᵀd < 0 for all i ∈ I(x*)

Interpretation: Feasible direction exists that strictly improves all active inequalities

4.4 Constant Rank Constraint Qualification (CRCQ):
--------------------------------------------------
Rank of constraint gradients is constant in neighborhood of x*

Weaker than LICQ but often easier to verify

4.5 Abadie Constraint Qualification (ACQ):
------------------------------------------
Tangent cone equals linearizing cone

Most general but difficult to verify in practice

4.6 Slater's Condition:
----------------------
For convex problems: ∃ x̂ such that gᵢ(x̂) < 0 for all i, hⱼ(x̂) = 0 for all j

Ensures strong duality and KKT conditions for convex programs

=======================================================

5. DUALITY THEORY
=================

5.1 Lagrangian Dual Function:
-----------------------------
For primal problem:
minimize f(x)
subject to g(x) ≤ 0, h(x) = 0

Dual function: q(μ, λ) = inf_x L(x, μ, λ) for μ ≥ 0

Properties:
- q is concave (even if primal is non-convex)
- q(μ, λ) ≤ p* for all μ ≥ 0 (weak duality)

5.2 Dual Problem:
----------------
maximize q(μ, λ)
subject to μ ≥ 0

Always convex optimization problem
Dual variables: (μ, λ)
Dual optimal value: d*

5.3 Weak and Strong Duality:
---------------------------
Weak duality: d* ≤ p* (always holds)
Duality gap: p* - d*

Strong duality: d* = p* (duality gap = 0)
Conditions for strong duality:
- Convex primal problem + Slater's condition
- Various other conditions for non-convex problems

5.4 Dual Interpretation:
-----------------------
Dual problem provides:
- Lower bounds on primal optimal value
- Sensitivity information (shadow prices)
- Alternative computational approaches

Economic interpretation:
- Primal: Resource allocation problem
- Dual: Pricing problem for resources

5.5 Complementary Slackness in Duality:
--------------------------------------
If strong duality holds and (x*, μ*, λ*) are primal-dual optimal:
μᵢ*gᵢ(x*) = 0 for all i

Interpretation:
- If primal constraint is slack, dual variable is zero
- If dual variable is positive, primal constraint is tight

=======================================================

6. COMPUTATIONAL METHODS FOR CONSTRAINED OPTIMIZATION
=====================================================

6.1 Penalty Methods:
-------------------
Transform constrained problem to unconstrained:
minimize f(x) + ρP(x)

where P(x) = Σᵢ max(0, gᵢ(x))² + Σⱼ hⱼ(x)² (quadratic penalty)

Algorithm:
1. Solve unconstrained problem for penalty parameter ρₖ
2. Increase ρₖ and repeat
3. Continue until convergence

Issues:
- Penalty parameter → ∞ causes ill-conditioning
- Exact solution only in limit

6.2 Augmented Lagrangian Methods:
--------------------------------
Combine Lagrangian and penalty approaches:
minimize L_ρ(x, λ, μ) = f(x) + λᵀh(x) + μᵀmax(0, g(x)) + ρ/2[||h(x)||² + ||max(0, g(x))||²]

Algorithm:
1. Minimize augmented Lagrangian for fixed (λₖ, μₖ, ρₖ)
2. Update multipliers based on constraint violations
3. Update penalty parameter if needed
4. Repeat until convergence

Advantages:
- Multiplier estimates improve
- Don't need ρ → ∞ for exact solution

6.3 Sequential Quadratic Programming (SQP):
------------------------------------------
Newton-like method for constrained optimization
At iteration k, solve quadratic subproblem:
minimize ∇f(xₖ)ᵀd + ½dᵀHₖd
subject to ∇g(xₖ)ᵀd + g(xₖ) ≤ 0
          ∇h(xₖ)ᵀd + h(xₖ) = 0

where Hₖ approximates Hessian of Lagrangian

Properties:
- Superlinear convergence
- Industry standard for smooth nonlinear programming
- Requires QP solver for subproblems

6.4 Interior Point Methods:
--------------------------
Add barrier to prevent constraint violations:
minimize f(x) - μΣᵢ log(-gᵢ(x))
subject to h(x) = 0

Algorithm:
1. Solve barrier problem for barrier parameter μₖ
2. Decrease μₖ and repeat
3. Approach boundary as μₖ → 0

Advantages:
- Polynomial complexity for convex problems
- Handle large-scale problems well
- Don't require feasible starting point

6.5 Active Set Methods:
----------------------
Idea: Guess which constraints are active at solution

Algorithm:
1. Solve equality-constrained problem with active constraints
2. Check KKT conditions
3. Add/remove constraints from active set
4. Repeat until optimal

Efficient for problems where active set doesn't change much

=======================================================

7. SPECIAL CASES AND APPLICATIONS
=================================

7.1 Linear Programming:
----------------------
minimize cᵀx
subject to Ax ≤ b
          x ≥ 0

KKT conditions become:
Aᵀy + s = c, Ax + w = b, x, s, y, w ≥ 0, xᵢsᵢ = 0, yⱼwⱼ = 0

Simplifies to optimality conditions for simplex method
Strong duality always holds (if feasible)

7.2 Quadratic Programming:
-------------------------
minimize ½xᵀQx + cᵀx
subject to Ax ≤ b
          Cx = d

KKT conditions:
Qx + c + Aᵀμ + Cᵀλ = 0
Ax ≤ b, Cx = d, μ ≥ 0, μᵢ(Ax - b)ᵢ = 0

If Q ≻ 0 (positive definite), then convex with unique solution

7.3 Semidefinite Programming:
----------------------------
minimize cᵀx
subject to F(x) = F₀ + Σᵢ xᵢFᵢ ⪰ 0
          Ax = b

where F(x) ⪰ 0 means F(x) is positive semidefinite

Generalization of linear programming
Applications: Relaxations of combinatorial problems, robust optimization

7.4 Convex Optimization:
-----------------------
If f and gᵢ are convex, hⱼ are affine:
- Any local optimum is global optimum
- KKT conditions are necessary and sufficient
- Strong duality holds under Slater's condition
- Efficient algorithms available

=======================================================

8. MACHINE LEARNING APPLICATIONS
================================

8.1 Support Vector Machines:
---------------------------
Primal problem:
minimize ½||w||² + C Σᵢ ξᵢ
subject to yᵢ(wᵀxᵢ + b) ≥ 1 - ξᵢ
          ξᵢ ≥ 0

Dual problem:
maximize Σᵢ αᵢ - ½ Σᵢⱼ αᵢαⱼyᵢyⱼxᵢᵀxⱼ
subject to Σᵢ αᵢyᵢ = 0
          0 ≤ αᵢ ≤ C

KKT conditions provide:
- Characterization of support vectors
- Sparsity of solution
- Kernel trick applicability

8.2 Regularized Regression:
--------------------------
Lasso (L1 regularization):
minimize ½||y - Xβ||² + λ||β||₁

Reformulate as:
minimize ½||y - Xβ||²
subject to ||β||₁ ≤ t

KKT conditions explain:
- When coefficients are exactly zero
- Solution path as λ varies
- Variable selection properties

8.3 Portfolio Optimization:
--------------------------
Mean-variance optimization:
minimize wᵀΣw
subject to wᵀμ ≥ r_min
          wᵀ1 = 1
          w ≥ 0 (optional)

Lagrangian analysis provides:
- Efficient frontier characterization
- Two-fund theorem
- Risk-return trade-offs

8.4 Constrained Clustering:
--------------------------
K-means with constraints:
minimize Σᵢⱼ ||xᵢ - cⱼ||²zᵢⱼ
subject to Σⱼ zᵢⱼ = 1 (assignment constraints)
          zᵢⱼ ∈ {0,1} (binary constraints)
          Additional domain constraints

Relaxations and penalty methods enable practical algorithms

8.5 Neural Network Training with Constraints:
--------------------------------------------
minimize L(θ) (training loss)
subject to g(θ) ≤ 0 (fairness, robustness, or other constraints)

Approaches:
- Penalty methods: Add constraint violations to loss
- Projected gradient descent: Project onto feasible set
- Augmented Lagrangian: Update multipliers during training

8.6 Hyperparameter Optimization:
-------------------------------
minimize Validation_Error(θ(λ))
subject to λ ∈ Λ (hyperparameter space)

where θ(λ) = argmin Training_Loss(θ; λ)

Bilevel optimization problem:
- Upper level: Hyperparameter selection
- Lower level: Model training
- Gradient-based methods use implicit differentiation

8.7 Domain Adaptation:
---------------------
minimize Source_Loss + Target_Loss
subject to Distribution_Distance ≤ ε

Enforces similarity between source and target distributions
Often formulated using optimal transport or MMD constraints

8.8 Federated Learning:
----------------------
minimize Σᵢ wᵢLᵢ(θ)
subject to Communication_Budget ≤ B
          Privacy_Constraints

Constraints arise from:
- Limited communication rounds
- Differential privacy requirements
- Fairness across clients

Key Insights for ML:
- Many ML problems naturally include constraints
- Lagrange multipliers provide interpretable sensitivity information
- Duality enables alternative algorithmic approaches
- Constraint handling crucial for practical deployments
- KKT conditions guide optimality analysis
- Convex relaxations often make problems tractable

=======================================================
END OF DOCUMENT 