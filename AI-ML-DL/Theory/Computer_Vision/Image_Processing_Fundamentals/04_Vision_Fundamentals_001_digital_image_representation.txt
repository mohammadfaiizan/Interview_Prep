DIGITAL IMAGE REPRESENTATION
===========================

Table of Contents:
1. Image Formation and Acquisition
2. Digital Image Structure and Properties
3. Pixel Representation and Data Types
4. Color Spaces and Models
5. Sampling and Quantization
6. Image Storage Formats and Compression
7. Resolution and Image Quality
8. Python Implementation Examples
9. Applications and Practical Considerations
10. Advanced Topics and Future Directions

================================================================================
1. IMAGE FORMATION AND ACQUISITION
================================================================================

1.1 Physical Image Formation
-----------------------------
Physical images are formed when light interacts with objects and is captured by a sensor:

- Light source illumination: f(x, y) = i(x, y) * r(x, y)
  where i(x, y) is illumination and r(x, y) is reflectance
- Sensor response: g(x, y) = ∫ f(x, y, λ) * s(λ) dλ
  where s(λ) is sensor spectral sensitivity

Key factors affecting image formation:
- Illumination conditions (natural/artificial light)
- Object surface properties (reflectance, texture)
- Imaging geometry (perspective, viewing angle)
- Optical system characteristics (lens, aperture, focus)

1.2 Image Acquisition Systems
-----------------------------
Common image acquisition devices:

**CCD/CMOS Sensors:**
- Charge-Coupled Device (CCD): High quality, low noise
- Complementary Metal-Oxide-Semiconductor (CMOS): Lower power, faster readout
- Quantum efficiency: η = (number of generated electrons) / (number of incident photons)

**Acquisition Process:**
1. Optical focusing
2. Spatial sampling (pixel array)
3. Temporal integration (exposure time)
4. Analog-to-digital conversion
5. Signal processing and enhancement

1.3 Geometric Image Formation
-----------------------------
**Pinhole Camera Model:**
- Perspective projection: [x', y', z'] = K[R|t][X, Y, Z, 1]ᵀ
- Camera matrix: K = [[fx, s, cx], [0, fy, cy], [0, 0, 1]]
- Distortion effects: radial and tangential

**Image Coordinate Systems:**
- World coordinates (X, Y, Z)
- Camera coordinates (Xc, Yc, Zc)
- Image coordinates (x, y)
- Pixel coordinates (u, v)

================================================================================
2. DIGITAL IMAGE STRUCTURE AND PROPERTIES
================================================================================

2.1 Digital Image Definition
-----------------------------
A digital image is a discrete 2D function f(x, y) where:
- x, y are spatial coordinates (integers)
- f(x, y) is the intensity value at position (x, y)
- Domain: x ∈ [0, M-1], y ∈ [0, N-1] for M×N image
- Range: f(x, y) ∈ [0, 2ᵇ-1] for b-bit quantization

**Mathematical Representation:**
```
f(x, y) = [f(0,0)   f(0,1)   ... f(0,N-1)  ]
          [f(1,0)   f(1,1)   ... f(1,N-1)  ]
          [  ...      ...    ...    ...    ]
          [f(M-1,0) f(M-1,1) ... f(M-1,N-1)]
```

2.2 Image Dimensions and Properties
-----------------------------------
**Spatial Properties:**
- Width (W): Number of columns
- Height (H): Number of rows
- Aspect ratio: W/H
- Total pixels: W × H

**Intensity Properties:**
- Bit depth: Number of bits per pixel
- Dynamic range: [min_value, max_value]
- Histogram: h(k) = number of pixels with intensity k

**Multi-channel Images:**
- Grayscale: f(x, y) - single channel
- Color: f(x, y, c) - multiple channels (RGB, etc.)
- Hyperspectral: f(x, y, λ) - many spectral bands

2.3 Neighborhood and Connectivity
----------------------------------
**Pixel Neighborhoods:**
- 4-neighborhood: N₄(p) = {(x±1, y), (x, y±1)}
- 8-neighborhood: N₈(p) = N₄(p) ∪ {(x±1, y±1)}
- Distance metrics:
  - Euclidean: d_E = √[(x₁-x₂)² + (y₁-y₂)²]
  - Manhattan: d_M = |x₁-x₂| + |y₁-y₂|
  - Chessboard: d_C = max(|x₁-x₂|, |y₁-y₂|)

**Connectivity:**
- 4-connected: pixels sharing an edge
- 8-connected: pixels sharing an edge or corner
- Applications in region analysis and morphology

================================================================================
3. PIXEL REPRESENTATION AND DATA TYPES
================================================================================

3.1 Integer Representations
----------------------------
**Unsigned Integers:**
- uint8: [0, 255] - most common for display
- uint16: [0, 65535] - medical imaging, astronomy
- uint32: [0, 4,294,967,295] - specialized applications

**Signed Integers:**
- int8: [-128, 127]
- int16: [-32768, 32767]
- Used for difference images, gradients

3.2 Floating-Point Representations
-----------------------------------
**Single Precision (float32):**
- Range: approximately [-3.4×10³⁸, 3.4×10³⁸]
- Common in scientific imaging and HDR

**Double Precision (float64):**
- Higher precision for calculations
- Used in research and analysis

**Normalized Representations:**
- [0.0, 1.0]: Common in machine learning
- [-1.0, 1.0]: Symmetric range for certain operations

3.3 Binary and Logical Images
------------------------------
**Binary Images:**
- Values: {0, 1} or {False, True}
- Used for masks, segmentation results
- Operations: AND, OR, NOT, XOR

**Conversion Between Types:**
```python
# uint8 to float32
float_img = uint8_img.astype(np.float32) / 255.0

# float32 to uint8
uint8_img = np.clip(float_img * 255.0, 0, 255).astype(np.uint8)
```

================================================================================
4. COLOR SPACES AND MODELS
================================================================================

4.1 RGB Color Space
-------------------
**Definition:**
- Additive color model
- Primary colors: Red, Green, Blue
- Cube representation in 3D space
- Range: [0, 255] for 8-bit per channel

**Properties:**
- Device-dependent
- Non-uniform perceptual space
- Linear combination: C = aR + bG + cB

**Transformations:**
- Grayscale conversion: Y = 0.299R + 0.587G + 0.114B
- Luminance-weighted: considers human visual sensitivity

4.2 HSV/HSL Color Spaces
------------------------
**HSV (Hue, Saturation, Value):**
- Cylindrical coordinate system
- Hue: [0°, 360°] - color type
- Saturation: [0, 1] - color purity
- Value: [0, 1] - brightness

**HSL (Hue, Saturation, Lightness):**
- Similar to HSV but different lightness definition
- More perceptually uniform than RGB
- Better for color-based image analysis

**RGB to HSV Conversion:**
```
C_max = max(R, G, B)
C_min = min(R, G, B)
Δ = C_max - C_min

V = C_max
S = 0 if C_max = 0, else Δ/C_max
H = calculated based on which of R, G, B is maximum
```

4.3 Perceptually Uniform Color Spaces
--------------------------------------
**CIELAB (L*a*b*):**
- Perceptually uniform
- L*: lightness [0, 100]
- a*: green-red axis [-128, 127]
- b*: blue-yellow axis [-128, 127]
- Better for color difference measurements

**CIELUV:**
- Alternative perceptually uniform space
- Used in specific applications like color management

4.4 Other Important Color Spaces
---------------------------------
**YUV/YCbCr:**
- Used in video compression (JPEG, MPEG)
- Y: luminance, U/V or Cb/Cr: chrominance
- Allows chroma subsampling

**CMYK:**
- Subtractive color model for printing
- Cyan, Magenta, Yellow, Key (black)

================================================================================
5. SAMPLING AND QUANTIZATION
================================================================================

5.1 Spatial Sampling
---------------------
**Sampling Theory:**
- Continuous to discrete conversion
- Sampling frequency: fs = 1/T where T is sampling interval
- Nyquist theorem: fs ≥ 2 × f_max to avoid aliasing

**Aliasing Effects:**
- Occurs when sampling rate is insufficient
- Creates false low-frequency components
- Manifestations: moiré patterns, staircase effects

**Anti-aliasing Techniques:**
- Pre-filtering before sampling
- Low-pass filter to remove high frequencies
- Super-sampling and averaging

5.2 Intensity Quantization
---------------------------
**Quantization Process:**
- Continuous intensity → discrete levels
- Uniform quantization: q = round(f / (f_max / (2ᵇ - 1)))
- Non-uniform quantization: adaptive based on statistics

**Quantization Error:**
- Round-off error: ε = f_quantized - f_original
- Signal-to-Noise Ratio: SNR = 20 log₁₀(signal_power/noise_power)
- Higher bit depth → lower quantization error

**Effects of Quantization:**
- False contouring with insufficient bits
- Loss of fine details
- Compression artifacts

5.3 Resolution Concepts
-----------------------
**Spatial Resolution:**
- Pixel density: pixels per inch (PPI) or dots per inch (DPI)
- Affects image sharpness and detail
- Trade-off: file size vs. quality

**Intensity Resolution:**
- Bit depth determines intensity levels
- 8-bit: 256 levels, 16-bit: 65,536 levels
- Medical imaging often uses 12-16 bits

**Temporal Resolution:**
- Frame rate in video sequences
- Important for motion analysis

================================================================================
6. IMAGE STORAGE FORMATS AND COMPRESSION
================================================================================

6.1 Uncompressed Formats
-------------------------
**BMP (Bitmap):**
- Simple, uncompressed
- Large file sizes
- Good for temporary storage

**TIFF (Tagged Image File Format):**
- Supports multiple bit depths
- Lossless compression options
- Professional photography and printing

**RAW Formats:**
- Unprocessed sensor data
- Maximum information retention
- Requires specialized software

6.2 Lossless Compression
-------------------------
**PNG (Portable Network Graphics):**
- Lossless compression
- Supports transparency
- Good for graphics and line art

**GIF (Graphics Interchange Format):**
- 8-bit color limitation
- Supports animation
- Good for simple graphics

**Compression Techniques:**
- Run-length encoding (RLE)
- LZ77/LZ78 algorithms
- Huffman coding

6.3 Lossy Compression
---------------------
**JPEG (Joint Photographic Experts Group):**
- DCT-based compression
- Variable quality settings
- Trade-off between file size and quality

**Compression Artifacts:**
- Blocking artifacts
- Ringing near edges
- Color bleeding

**Quality Assessment:**
- PSNR: Peak Signal-to-Noise Ratio
- SSIM: Structural Similarity Index
- Human visual system considerations

================================================================================
7. RESOLUTION AND IMAGE QUALITY
================================================================================

7.1 Image Quality Metrics
--------------------------
**Objective Metrics:**
- Signal-to-Noise Ratio (SNR)
- Peak Signal-to-Noise Ratio (PSNR): 20 log₁₀(MAX²/MSE)
- Mean Squared Error (MSE)
- Structural Similarity Index (SSIM)

**Subjective Quality:**
- Human visual perception
- Just-noticeable difference (JND)
- Viewing conditions effects

7.2 Factors Affecting Quality
-----------------------------
**Acquisition Factors:**
- Sensor characteristics
- Optical system quality
- Lighting conditions
- Motion blur

**Processing Factors:**
- Compression algorithms
- Interpolation methods
- Enhancement operations
- Noise introduction

7.3 Resolution Enhancement
--------------------------
**Interpolation Methods:**
- Nearest neighbor: simple, preserves edges
- Bilinear: smooth, blurred edges
- Bicubic: smoother, better quality
- Lanczos: high-quality resampling

**Super-resolution Techniques:**
- Multi-frame super-resolution
- Learning-based methods
- Edge-preserving techniques

================================================================================
8. PYTHON IMPLEMENTATION EXAMPLES
================================================================================

```python
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import cv2
from skimage import io, color, transform

class DigitalImage:
    """Class for digital image representation and basic operations"""
    
    def __init__(self, data, color_space='RGB'):
        """
        Initialize digital image
        
        Args:
            data: numpy array representing image data
            color_space: string indicating color space
        """
        self.data = np.array(data)
        self.color_space = color_space
        self.shape = self.data.shape
        self.dtype = self.data.dtype
        
    def get_properties(self):
        """Get basic image properties"""
        properties = {
            'shape': self.shape,
            'dtype': self.dtype,
            'color_space': self.color_space,
            'size_bytes': self.data.nbytes,
            'min_value': np.min(self.data),
            'max_value': np.max(self.data),
            'mean_value': np.mean(self.data)
        }
        
        if len(self.shape) == 2:
            properties['type'] = 'grayscale'
            properties['channels'] = 1
        elif len(self.shape) == 3:
            properties['type'] = 'color'
            properties['channels'] = self.shape[2]
        
        return properties
    
    def convert_dtype(self, target_dtype):
        """Convert image data type with proper scaling"""
        
        if self.dtype == target_dtype:
            return self
        
        # Get source and target ranges
        src_info = np.iinfo(self.dtype) if np.issubdtype(self.dtype, np.integer) else None
        tgt_info = np.iinfo(target_dtype) if np.issubdtype(target_dtype, np.integer) else None
        
        if src_info and tgt_info:
            # Integer to integer conversion
            scale_factor = tgt_info.max / src_info.max
            converted_data = (self.data * scale_factor).astype(target_dtype)
        elif src_info and not tgt_info:
            # Integer to float conversion
            converted_data = self.data.astype(target_dtype) / src_info.max
        elif not src_info and tgt_info:
            # Float to integer conversion
            converted_data = (np.clip(self.data, 0, 1) * tgt_info.max).astype(target_dtype)
        else:
            # Float to float conversion
            converted_data = self.data.astype(target_dtype)
        
        return DigitalImage(converted_data, self.color_space)
    
    def to_grayscale(self, method='luminance'):
        """Convert color image to grayscale"""
        
        if len(self.shape) == 2:
            return self  # Already grayscale
        
        if self.color_space == 'RGB':
            if method == 'average':
                gray_data = np.mean(self.data, axis=2)
            elif method == 'luminance':
                # ITU-R BT.601 standard
                weights = np.array([0.299, 0.587, 0.114])
                gray_data = np.dot(self.data, weights)
            elif method == 'desaturation':
                gray_data = (np.max(self.data, axis=2) + np.min(self.data, axis=2)) / 2
        else:
            # Convert to RGB first, then to grayscale
            rgb_img = self.convert_color_space('RGB')
            return rgb_img.to_grayscale(method)
        
        return DigitalImage(gray_data, 'GRAY')
    
    def convert_color_space(self, target_space):
        """Convert between color spaces"""
        
        if self.color_space == target_space:
            return self
        
        # Convert to float for processing
        float_data = self.data.astype(np.float32)
        if np.max(float_data) > 1.0:
            float_data = float_data / 255.0
        
        if self.color_space == 'RGB' and target_space == 'HSV':
            # RGB to HSV conversion
            converted_data = color.rgb2hsv(float_data)
        elif self.color_space == 'HSV' and target_space == 'RGB':
            # HSV to RGB conversion
            converted_data = color.hsv2rgb(float_data)
        elif self.color_space == 'RGB' and target_space == 'LAB':
            # RGB to LAB conversion
            converted_data = color.rgb2lab(float_data)
        elif self.color_space == 'LAB' and target_space == 'RGB':
            # LAB to RGB conversion
            converted_data = color.lab2rgb(float_data)
        else:
            raise ValueError(f"Conversion from {self.color_space} to {target_space} not implemented")
        
        # Convert back to original data type
        if self.dtype == np.uint8:
            converted_data = (converted_data * 255).astype(np.uint8)
        
        return DigitalImage(converted_data, target_space)
    
    def compute_histogram(self, bins=256):
        """Compute image histogram"""
        
        if len(self.shape) == 2:
            # Grayscale histogram
            hist, bin_edges = np.histogram(self.data.flatten(), bins=bins)
            return hist, bin_edges
        else:
            # Multi-channel histogram
            histograms = []
            for channel in range(self.shape[2]):
                hist, bin_edges = np.histogram(self.data[:, :, channel].flatten(), bins=bins)
                histograms.append((hist, bin_edges))
            return histograms
    
    def resize(self, new_size, method='bilinear'):
        """Resize image using different interpolation methods"""
        
        if method == 'nearest':
            order = 0
        elif method == 'bilinear':
            order = 1
        elif method == 'bicubic':
            order = 3
        else:
            raise ValueError(f"Unknown interpolation method: {method}")
        
        # Calculate scale factors
        scale_y = new_size[0] / self.shape[0]
        scale_x = new_size[1] / self.shape[1]
        
        if len(self.shape) == 2:
            # Grayscale image
            resized_data = transform.rescale(self.data, (scale_y, scale_x), 
                                           order=order, preserve_range=True)
        else:
            # Color image
            resized_data = transform.rescale(self.data, (scale_y, scale_x, 1), 
                                           order=order, preserve_range=True)
        
        return DigitalImage(resized_data.astype(self.dtype), self.color_space)

def demonstrate_image_properties():
    """Demonstrate digital image properties and operations"""
    
    # Create a synthetic test image
    test_image = create_test_image()
    
    # Display properties
    props = test_image.get_properties()
    print("Image Properties:")
    for key, value in props.items():
        print(f"  {key}: {value}")
    
    # Convert data types
    float_image = test_image.convert_dtype(np.float32)
    print(f"Converted to float32: {float_image.get_properties()['dtype']}")
    
    # Convert to grayscale
    gray_image = test_image.to_grayscale('luminance')
    print(f"Grayscale shape: {gray_image.shape}")
    
    # Convert color spaces
    hsv_image = test_image.convert_color_space('HSV')
    print(f"HSV color space: {hsv_image.color_space}")
    
    # Compute histogram
    hist, bins = gray_image.compute_histogram()
    print(f"Histogram shape: {hist.shape}")
    
    # Resize image
    resized_image = test_image.resize((128, 128), 'bicubic')
    print(f"Resized shape: {resized_image.shape}")

def create_test_image(size=(256, 256)):
    """Create a synthetic test image for demonstration"""
    
    # Create test pattern with gradients and geometric shapes
    y, x = np.ogrid[:size[0], :size[1]]
    
    # Create RGB channels with different patterns
    r_channel = (x / size[1] * 255).astype(np.uint8)  # Horizontal gradient
    g_channel = (y / size[0] * 255).astype(np.uint8)  # Vertical gradient
    
    # Create circular pattern for blue channel
    center_x, center_y = size[1] // 2, size[0] // 2
    radius = min(size) // 4
    distance = np.sqrt((x - center_x)**2 + (y - center_y)**2)
    b_channel = (255 * (distance < radius)).astype(np.uint8)
    
    # Combine channels
    test_data = np.stack([r_channel, g_channel, b_channel], axis=2)
    
    return DigitalImage(test_data, 'RGB')

def analyze_image_quality(image1, image2):
    """Analyze quality differences between two images"""
    
    # Ensure same data type and range
    img1 = image1.convert_dtype(np.float64).data
    img2 = image2.convert_dtype(np.float64).data
    
    # Normalize to [0, 1] range
    img1 = img1 / 255.0 if np.max(img1) > 1.0 else img1
    img2 = img2 / 255.0 if np.max(img2) > 1.0 else img2
    
    # Mean Squared Error
    mse = np.mean((img1 - img2) ** 2)
    
    # Peak Signal-to-Noise Ratio
    if mse == 0:
        psnr = float('inf')
    else:
        psnr = 20 * np.log10(1.0 / np.sqrt(mse))
    
    # Structural Similarity Index (simplified version)
    mu1, mu2 = np.mean(img1), np.mean(img2)
    sigma1, sigma2 = np.std(img1), np.std(img2)
    sigma12 = np.mean((img1 - mu1) * (img2 - mu2))
    
    c1, c2 = 0.01**2, 0.03**2
    ssim = ((2*mu1*mu2 + c1) * (2*sigma12 + c2)) / ((mu1**2 + mu2**2 + c1) * (sigma1**2 + sigma2**2 + c2))
    
    return {
        'MSE': mse,
        'PSNR': psnr,
        'SSIM': ssim
    }

# Example usage and testing
if __name__ == "__main__":
    # Demonstrate digital image concepts
    demonstrate_image_properties()
    
    # Create and analyze test images
    original = create_test_image()
    compressed = original.resize((128, 128)).resize((256, 256))
    
    quality_metrics = analyze_image_quality(original, compressed)
    print("\nQuality Analysis:")
    for metric, value in quality_metrics.items():
        print(f"  {metric}: {value:.4f}")
```

================================================================================
9. APPLICATIONS AND PRACTICAL CONSIDERATIONS
================================================================================

9.1 Medical Imaging
--------------------
**DICOM Format:**
- Medical image standard
- Metadata for patient information
- 12-16 bit depth common
- Lossless compression requirements

**Modality-Specific Considerations:**
- CT: Hounsfield units, window/level adjustments
- MRI: Multiple sequences, complex-valued data
- X-ray: High dynamic range, noise characteristics

9.2 Scientific Imaging
-----------------------
**Astronomical Imaging:**
- High bit depth (16-bit common)
- Noise characteristics important
- Calibration frames (dark, flat, bias)

**Microscopy:**
- Multi-channel fluorescence
- Time-lapse sequences
- 3D volume reconstruction

9.3 Digital Photography
-----------------------
**RAW Processing:**
- Demosaicing algorithms
- White balance correction
- Exposure compensation
- Color profile management

**HDR Imaging:**
- Multiple exposure fusion
- Tone mapping algorithms
- Extended dynamic range

9.4 Machine Learning Applications
----------------------------------
**Data Preprocessing:**
- Normalization strategies
- Data augmentation considerations
- Batch processing requirements

**Input Format Considerations:**
- Channel ordering (HWC vs CHW)
- Data type requirements (float32 common)
- Memory efficiency

================================================================================
10. ADVANCED TOPICS AND FUTURE DIRECTIONS
================================================================================

10.1 High Dynamic Range (HDR)
------------------------------
**HDR Representation:**
- Extended intensity range
- Tone mapping for display
- Perceptual encoding

**Applications:**
- Professional photography
- Computer graphics
- Automotive imaging

10.2 Computational Photography
-------------------------------
**Multi-frame Processing:**
- Image alignment and fusion
- Noise reduction through averaging
- Resolution enhancement

**Light Field Imaging:**
- 4D light field representation
- Refocusing after capture
- Depth information extraction

10.3 Emerging Technologies
--------------------------
**Quantum Imaging:**
- Quantum-enhanced sensors
- Single-photon detection
- Noise reduction benefits

**AI-Enhanced Processing:**
- Deep learning for super-resolution
- Intelligent compression
- Content-aware processing

**Immersive Media:**
- 360-degree panoramic imaging
- Virtual/Augmented Reality
- Volumetric capture

10.4 Future Standards and Formats
----------------------------------
**Next-Generation Formats:**
- HEIF (High Efficiency Image Format)
- AVIF (AV1 Image File Format)
- JPEG XL (next-generation JPEG)

**Advanced Color Spaces:**
- Wide color gamut support
- HDR color spaces (Rec. 2020, Rec. 2100)
- Perceptual uniformity improvements

================================================================================
CONCLUSION
================================================================================

Digital image representation forms the foundation of all computer vision and image processing tasks. Understanding the fundamental concepts of:

- Image formation and acquisition physics
- Digital sampling and quantization theory
- Color space mathematics and perceptual considerations
- Data type optimization and memory management
- Quality metrics and compression trade-offs

is essential for developing robust and efficient image processing systems.

The field continues to evolve with advances in sensor technology, computational methods, and AI-driven processing techniques. Future developments will likely focus on:

- Higher dynamic range and improved color accuracy
- More efficient compression algorithms
- AI-integrated acquisition and processing pipelines
- Immersive and volumetric imaging technologies

Mastery of these fundamental concepts provides the necessary foundation for advanced computer vision research and practical applications across diverse domains including medical imaging, autonomous systems, entertainment, and scientific research.

================================================================================
REFERENCES AND FURTHER READING
================================================================================

1. Gonzalez, R.C. & Woods, R.E. "Digital Image Processing" (4th Edition)
2. Szeliski, R. "Computer Vision: Algorithms and Applications" (2nd Edition)
3. Reinhard, E. et al. "High Dynamic Range Imaging" (2nd Edition)
4. Burger, W. & Burge, M.J. "Digital Image Processing: An Algorithmic Introduction"
5. Petrou, M. & Petrou, C. "Image Processing: The Fundamentals" (2nd Edition)
6. ISO/IEC 23008 (HEVC/H.265) and related imaging standards
7. ITU-R Recommendations for color and imaging standards
8. Recent papers on computational photography and AI-enhanced imaging 